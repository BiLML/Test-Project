# backend/main.py
import requests
import os
import asyncio
import numpy as np
import cv2 
from dotenv import load_dotenv
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from motor.motor_asyncio import AsyncIOMotorClient
import bcrypt
from jose import JWTError, jwt
from datetime import datetime, timedelta
from fastapi import FastAPI, HTTPException, Depends, status, File, UploadFile, BackgroundTasks
from fastapi.security import OAuth2PasswordBearer
import cloudinary
import cloudinary.uploader
from bson.objectid import ObjectId
import io
import tensorflow as tf
# Import ƒë·ªÉ x·ª≠ l√Ω ·∫£nh cho model c≈© (n·∫øu d√πng EfficientNet)
from tensorflow.keras.applications.efficientnet import preprocess_input

# 1. Load bi·∫øn m√¥i tr∆∞·ªùng
load_dotenv()

# 2. Kh·ªüi t·∫°o App
app = FastAPI()

# 3. C·∫•u h√¨nh CORS
origins = ["http://localhost:5173"]
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# 4. K·∫øt n·ªëi Database
MONGO_URL = os.getenv("MONGO_URL", "mongodb://localhost:27017")
client = AsyncIOMotorClient(MONGO_URL)
db = client.aura_db
users_collection = db.users
medical_records_collection = db.medical_records

# 5. C·∫•u h√¨nh B·∫£o m·∫≠t
SECRET_KEY = os.getenv("SECRET_KEY", "secret_mac_dinh")
ALGORITHM = os.getenv("ALGORITHM", "HS256")
ACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv("ACCESS_TOKEN_EXPIRE_MINUTES", 30))

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="/api/login")

# 6. C·∫•u h√¨nh Cloudinary
cloudinary.config( 
    cloud_name = os.getenv("CLOUDINARY_CLOUD_NAME"), 
    api_key = os.getenv("CLOUDINARY_API_KEY"), 
    api_secret = os.getenv("CLOUDINARY_API_SECRET"),
    secure = True
)

# ==============================================================================
# üß† KH·ªûI T·∫†O H·ªÜ TH·ªêNG AURA AI (HYBRID ENSEMBLE: SEGMENTATION + CLASSIFICATION)
# ==============================================================================

# C·∫•u h√¨nh danh s√°ch model
MODEL_PATHS = {
    # --- ƒê·ªòI QU√ÇN M·ªöI (Segmentation - Chuy√™n gia chi ti·∫øt) ---
    'EX': 'unet_mega_fusion.keras',      # Xu·∫•t ti·∫øt c·ª©ng
    'HE': 'unet_hemorrhages.keras',      # Xu·∫•t huy·∫øt
    'SE': 'unet_soft_exudates.keras',    # Xu·∫•t ti·∫øt m·ªÅm
    'MA': 'unet_microaneurysms.keras',   # Vi ph√¨nh m·∫°ch
    'OD': 'unet_optic_disc.keras',       # ƒêƒ©a th·ªã
    'Vessels': 'unet_vessels_pro.keras', # M·∫°ch m√°u Pro
    
    # --- L√ÉO T∆Ø·ªöNG (Classification - Chuy√™n gia t·ªïng quan) ---
    'CLASSIFIER': 'aura_retinal_model_final.keras' 
}

loaded_models = {}

print("‚è≥ ƒêANG KH·ªûI ƒê·ªòNG H·ªÜ TH·ªêNG AURA AI (CH·∫æ ƒê·ªò LAI)...")
for name, path in MODEL_PATHS.items():
    if os.path.exists(path):
        try:
            # compile=False ƒë·ªÉ tr√°nh l·ªói h√†m loss t√πy ch·ªânh khi load
            loaded_models[name] = tf.keras.models.load_model(path, compile=False)
            print(f"   ‚úÖ ƒê√£ t·∫£i Module: {name}")
        except Exception as e:
            print(f"   ‚ùå L·ªói t·∫£i {name}: {e}")
    else:
        print(f"   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y file model: {path}")

print(f"üöÄ AURA S·∫¥N S√ÄNG! ({len(loaded_models)}/{len(MODEL_PATHS)} modules ho·∫°t ƒë·ªông)")

# --- C√ÅC H√ÄM X·ª¨ L√ù ·∫¢NH ---

def preprocess_for_segmentation(img_array, target_size=256):
    """Chu·∫©n h√≥a ·∫£nh cho c√°c model t·ªïn th∆∞∆°ng (EX, HE, SE, MA, OD)"""
    img = cv2.resize(img_array, (target_size, target_size))
    img = img / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
    img = np.expand_dims(img, axis=0) # Th√™m chi·ªÅu batch
    return img

def preprocess_for_vessels_pro(img_array):
    """X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho M·∫°ch m√°u (K√™nh xanh + CLAHE + 512px)"""
    img = cv2.resize(img_array, (512, 512))
    green_channel = img[:, :, 1]
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced_img = clahe.apply(green_channel)
    enhanced_img = enhanced_img / 255.0
    enhanced_img = np.expand_dims(enhanced_img, axis=-1)
    enhanced_img = np.expand_dims(enhanced_img, axis=0)
    return enhanced_img

def preprocess_for_classifier(img_array):
    """X·ª≠ l√Ω cho model ph√¢n lo·∫°i c≈© (Ben Graham + 224px)"""
    img = cv2.resize(img_array, (224, 224))
    img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0,0), 10), -4, 128)
    img = preprocess_input(img) # Chu·∫©n c·ªßa EfficientNet
    img = np.expand_dims(img, axis=0)
    return img

# --- H√ÄM L·ªåC NHI·ªÑU (M·ªöI) ---
def clean_mask(mask_array, min_size=20):
    """
    Lo·∫°i b·ªè c√°c ƒë·ªëm tr·∫Øng nh·ªè h∆°n min_size pixel (coi l√† nhi·ªÖu).
    Gi·ªØ l·∫°i c√°c c·ª•m l·ªõn (t·ªïn th∆∞∆°ng th·∫≠t).
    """
    # Mask ƒë·∫ßu v√†o l√† float [0,1], c·∫ßn chuy·ªÉn v·ªÅ uint8 [0,255]
    mask_uint8 = (mask_array * 255).astype(np.uint8)
    
    # T√¨m c√°c v√πng li√™n th√¥ng (Connected Components)
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask_uint8, connectivity=8)
    
    # T·∫°o mask s·∫°ch
    cleaned_mask = np.zeros_like(mask_uint8)
    
    # Duy·ªát qua c√°c v√πng (b·ªè qua label 0 l√† n·ªÅn ƒëen)
    for i in range(1, num_labels):
        area = stats[i, cv2.CC_STAT_AREA]
        if area >= min_size: # Ch·ªâ gi·ªØ l·∫°i ƒë·ªëm l·ªõn h∆°n ng∆∞·ª°ng
            cleaned_mask[labels == i] = 255
            
    # Tr·∫£ v·ªÅ d·∫°ng float [0,1] nh∆∞ c≈©
    return cleaned_mask.astype(np.float32) / 255.0

# --- H√ÄM INFERENCE V2 (ƒê√É UPDATE LOGIC CH·ªêNG NHI·ªÑU) ---
def run_aura_inference(image_bytes):
    # 1. ƒê·ªçc ·∫£nh
    nparr = np.frombuffer(image_bytes, np.uint8)
    original_img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    original_rgb = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)
    
    OUT_SIZE = 256
    
    # Preprocess
    input_standard = preprocess_for_segmentation(original_rgb, target_size=OUT_SIZE)
    input_vessels = preprocess_for_vessels_pro(original_rgb)
    input_classifier = preprocess_for_classifier(original_rgb)
    
    findings = {}
    combined_mask = np.zeros((OUT_SIZE, OUT_SIZE, 3))
    
    # --- PH·∫¶N 1: CH·∫†Y SEGMENTATION & L·ªåC NHI·ªÑU ---
    
    # 1. M·∫°ch m√°u
    if 'Vessels' in loaded_models:
        pred = loaded_models['Vessels'].predict(input_vessels, verbose=0)[0]
        pred = cv2.resize(pred, (OUT_SIZE, OUT_SIZE))
        mask = (pred > 0.5).astype(np.float32) # Kh√¥ng l·ªçc nhi·ªÖu m·∫°ch m√°u v√¨ n√≥ v·ªën m·∫£nh
        findings['Vessels_Density'] = np.sum(mask)
        combined_mask[:,:,1] = np.maximum(combined_mask[:,:,1], mask) 

    # 2. ƒêƒ©a th·ªã
    if 'OD' in loaded_models:
        pred = loaded_models['OD'].predict(input_standard, verbose=0)[0,:,:,0]
        mask = (pred > 0.5).astype(np.float32)
        findings['OD_Area'] = np.sum(mask)
        combined_mask[:,:,2] = np.maximum(combined_mask[:,:,2], mask)

    # 3. T·ªïn th∆∞∆°ng ƒê·ªè (HE, MA) - C·∫¶N L·ªåC NHI·ªÑU K·ª∏
    if 'HE' in loaded_models:
        pred = loaded_models['HE'].predict(input_standard, verbose=0)[0,:,:,0]
        raw_mask = (pred > 0.5).astype(np.float32)
        mask = clean_mask(raw_mask, min_size=15) # L·ªçc ƒë·ªëm < 15px
        findings['HE_Count'] = np.sum(mask)
        combined_mask[:,:,0] = np.maximum(combined_mask[:,:,0], mask)

    if 'MA' in loaded_models:
        pred = loaded_models['MA'].predict(input_standard, verbose=0)[0,:,:,0]
        # MA r·∫•t nh·ªè, n√™n ng∆∞·ª°ng mask th·∫•p (0.2) nh∆∞ng l·ªçc size ph·∫£i kh√©o
        raw_mask = (pred > 0.2).astype(np.float32)
        mask = clean_mask(raw_mask, min_size=5) # Gi·ªØ ƒë·ªëm nh·ªè nh∆∞ng ph·∫£i r√µ n√©t
        findings['MA_Count'] = np.sum(mask)
        combined_mask[:,:,0] = np.maximum(combined_mask[:,:,0], mask)

    # 4. T·ªïn th∆∞∆°ng V√†ng (EX, SE)
    if 'EX' in loaded_models:
        pred = loaded_models['EX'].predict(input_standard, verbose=0)[0,:,:,0]
        raw_mask = (pred > 0.5).astype(np.float32)
        mask = clean_mask(raw_mask, min_size=20)
        findings['EX_Count'] = np.sum(mask)
        combined_mask[:,:,0] = np.maximum(combined_mask[:,:,0], mask)
        combined_mask[:,:,1] = np.maximum(combined_mask[:,:,1], mask)

    if 'SE' in loaded_models:
        pred = loaded_models['SE'].predict(input_standard, verbose=0)[0,:,:,0]
        raw_mask = (pred > 0.3).astype(np.float32)
        mask = clean_mask(raw_mask, min_size=20)
        findings['SE_Count'] = np.sum(mask)
        combined_mask[:,:,0] = np.maximum(combined_mask[:,:,0], mask)
        combined_mask[:,:,1] = np.maximum(combined_mask[:,:,1], mask)

    # --- PH·∫¶N 2: CH·∫†Y CLASSIFICATION ---
    classifier_result = "Kh√¥ng x√°c ƒë·ªãnh"
    classifier_confidence = 0.0
    
    if 'CLASSIFIER' in loaded_models:
        preds = loaded_models['CLASSIFIER'].predict(input_classifier, verbose=0)
        class_idx = np.argmax(preds[0])
        classifier_confidence = float(np.max(preds[0]))
        CLASS_MAP = {0: "B√¨nh th∆∞·ªùng (No DR)", 1: "Nh·∫π (Mild)", 2: "Trung b√¨nh (Moderate)", 3: "N·∫∑ng (Severe)", 4: "TƒÉng sinh (Proliferative)"}
        classifier_result = CLASS_MAP.get(class_idx, "Kh√¥ng x√°c ƒë·ªãnh")

    # --- PH·∫¶N 3: LOGIC H·ªòI CH·∫®N TH√îNG MINH (SMART ENSEMBLE) ---
    
    he_count = findings.get('HE_Count', 0)
    ma_count = findings.get('MA_Count', 0)
    se_count = findings.get('SE_Count', 0)
    ex_count = findings.get('EX_Count', 0)
    vessels_density = findings.get('Vessels_Density', 5000)
    od_area = findings.get('OD_Area', 0)

    # Logic ƒë·∫øm s·ªë l∆∞·ª£ng (ƒê√£ n√¢ng ng∆∞·ª°ng an to√†n)
    seg_diagnosis = "B√¨nh th∆∞·ªùng (No DR)"
    dr_score = 0

    if he_count > 800 or se_count > 200: 
        seg_diagnosis = "N·∫∑ng (Severe NPDR)"; dr_score = 3
    elif he_count > 80 or ex_count > 150: 
        seg_diagnosis = "Trung b√¨nh (Moderate NPDR)"; dr_score = 2
    elif ma_count > 20 or he_count > 20: 
        seg_diagnosis = "Nh·∫π (Mild NPDR)"; dr_score = 1
    
    # --- LOGIC QUY·∫æT ƒê·ªäNH CU·ªêI C√ôNG (QUAN TR·ªåNG) ---
    final_diagnosis = seg_diagnosis
    warning_note = ""
    
    # 1. N·∫øu Model c≈© c·ª±c k·ª≥ t·ª± tin l√† B√åNH TH∆Ø·ªúNG (>85%)
    if "B√¨nh th∆∞·ªùng" in classifier_result and classifier_confidence > 0.85:
        # M√† Model m·ªõi ch·ªâ th·∫•y "Nh·∫π" (do nhi·ªÖu ho·∫∑c qu√° nh·∫°y)
        if seg_diagnosis == "Nh·∫π (Mild NPDR)":
            # => √âP V·ªÄ B√åNH TH∆Ø·ªúNG (Coi l√† nhi·ªÖu d∆∞∆°ng t√≠nh gi·∫£)
            final_diagnosis = "B√¨nh th∆∞·ªùng (No DR)"
            dr_score = 0
            warning_note = "\n‚úÖ ƒê√£ l·ªçc nhi·ªÖu: C√°c vi t·ªïn th∆∞∆°ng ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°nh gi√° l√† kh√¥ng ƒë√°ng k·ªÉ."
    
    # 2. Ng∆∞·ª£c l·∫°i, n·∫øu Model c≈© th·∫•y "N·∫∑ng" m√† Segmentation kh√¥ng th·∫•y g√¨
    elif "N·∫∑ng" in classifier_result and seg_diagnosis == "B√¨nh th∆∞·ªùng (No DR)":
        final_diagnosis = f"Nghi ng·ªù {classifier_result}"
        warning_note = "\n‚ö†Ô∏è C·∫¢NH B√ÅO: AI t·ªïng quan th·∫•y d·∫•u hi·ªáu b·ªánh n·∫∑ng d√π t·ªïn th∆∞∆°ng ch∆∞a r√µ r√†ng tr√™n b·∫£n ƒë·ªì."
        dr_score = 3

    # --- T·ªîNG H·ª¢P B√ÅO C√ÅO Y KHOA ---
    risk_report = []
    
    # A. TI·ªÇU ƒê∆Ø·ªúNG
    if dr_score >= 1:
        risk_report.append(f"ü©∏ TI·ªÇU ƒê∆Ø·ªúNG: Ph√°t hi·ªán bi·∫øn ch·ª©ng ({final_diagnosis}).")
        if dr_score >= 3: risk_report.append("   ‚ûú C·∫¢NH B√ÅO: Ki·ªÉm so√°t ƒë∆∞·ªùng huy·∫øt k√©m. Nguy c∆° bi·∫øn ch·ª©ng th·∫≠n/th·∫ßn kinh.")
        elif dr_score == 2: risk_report.append("   ‚ûú B·ªánh ƒëang ti·∫øn tri·ªÉn. C·∫ßn ƒëi·ªÅu ch·ªânh l·ªëi s·ªëng.")
        else: risk_report.append("   ‚ûú Giai ƒëo·∫°n ƒë·∫ßu. Theo d√µi ƒë·ªãnh k·ª≥.")
    else:
        risk_report.append("ü©∏ TI·ªÇU ƒê∆Ø·ªúNG: V√µng m·∫°c kh·ªèe m·∫°nh (Ch∆∞a ph√°t hi·ªán b·ªánh l√Ω).")

    # B. TIM M·∫†CH
    risk_report.append("\n‚ù§Ô∏è TIM M·∫†CH & HUY·∫æT √ÅP:")
    if vessels_density < 2000: risk_report.append("‚ö†Ô∏è C·∫¢NH B√ÅO: M·∫°ch m√°u th∆∞a/h·∫πp. Nguy c∆° Cao huy·∫øt √°p.")
    elif vessels_density > 15000: risk_report.append("‚ö†Ô∏è C·∫¢NH B√ÅO: M·∫°ch m√°u gi√£n b·∫•t th∆∞·ªùng.")
    else: risk_report.append("‚úÖ H·ªá th·ªëng m·∫°ch m√°u ·ªïn ƒë·ªãnh.")

    # C. GLOCOM
    if od_area > 4500: risk_report.append("\nüëÅÔ∏è GLOCOM: ‚ö†Ô∏è K√≠ch th∆∞·ªõc ƒëƒ©a th·ªã l·ªõn, nghi ng·ªù l√µm gai.")

    # T·∫°o ·∫£nh Overlay
    img_resized = cv2.resize(original_rgb, (OUT_SIZE, OUT_SIZE)).astype(np.float32) / 255.0
    overlay = img_resized * (1 - combined_mask * 0.4) + combined_mask * 0.5
    overlay = np.clip(overlay * 255, 0, 255).astype(np.uint8)
    overlay_bgr = cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR)
    
    diagnosis_text = final_diagnosis
    detailed_risk_text = "\n".join(risk_report) + warning_note
    detailed_risk_text += f"\n\n--- TH√îNG S·ªê K·ª∏ THU·∫¨T ---\n‚Ä¢ HE: {int(he_count)} | MA: {int(ma_count)} | EX+SE: {int(ex_count+se_count)}"

    return overlay_bgr, diagnosis_text, detailed_risk_text

# ==============================================================================

# --- T√ÅC V·ª§ NG·∫¶M: AI PH√ÇN T√çCH TH·ª∞C T·∫æ ---
async def real_ai_analysis(record_id: str, image_url: str):
    print(f"ü§ñ AI AURA ƒëang ph√¢n t√≠ch h·ªì s∆°: {record_id}...")
    
    if not loaded_models:
        print("‚ö†Ô∏è Kh√¥ng c√≥ model n√†o ƒë∆∞·ª£c t·∫£i. H·ªßy ph√¢n t√≠ch.")
        return

    try:
        # 1. T·∫£i ·∫£nh t·ª´ Cloudinary
        response = requests.get(image_url)
        if response.status_code != 200: raise Exception("L·ªói t·∫£i ·∫£nh Cloudinary")
        image_bytes = response.content

        # 2. CH·∫†Y AURA INFERENCE (HYBRID MODE)
        overlay_img, diagnosis_result, detailed_risk = run_aura_inference(image_bytes)
        
        # 3. Upload ·∫£nh k·∫øt qu·∫£ (Overlay) l√™n Cloudinary
        is_success, buffer = cv2.imencode(".png", overlay_img)
        if not is_success: raise Exception("L·ªói m√£ h√≥a ·∫£nh k·∫øt qu·∫£.")
        annotated_file = io.BytesIO(buffer.tobytes())
        
        upload_result = cloudinary.uploader.upload(
            file=annotated_file, 
            public_id=f"aura_scan_{record_id}", 
            folder="aura_results",
            resource_type="image"
        )
        annotated_url = upload_result.get("secure_url")
        print(f"‚úÖ ·∫¢nh ph√¢n t√≠ch ƒë√£ l∆∞u: {annotated_url}")
        
        # 4. C·∫≠p nh·∫≠t DB
        await medical_records_collection.update_one(
            {"_id": ObjectId(record_id)},
            {
                "$set": {
                    "ai_analysis_status": "COMPLETED",
                    "ai_result": diagnosis_result,
                    "doctor_note": detailed_risk,
                    "annotated_image_url": annotated_url
                }
            }
        )
        print(f"‚úÖ H·ªì s∆° {record_id} ho√†n t·∫•t.")
    
    except Exception as e:
        print(f"‚ùå L·ªói AI: {e}")
        await medical_records_collection.update_one(
            {"_id": ObjectId(record_id)},
            {"$set": {"ai_analysis_status": "FAILED", "ai_result": "L·ªói ph√¢n t√≠ch"}}
        )

# --- C√ÅC H√ÄM H·ªñ TR·ª¢ & API AUTH (GI·ªÆ NGUY√äN) ---

def create_access_token(data: dict):
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)
    return encoded_jwt

async def get_current_user(token: str = Depends(oauth2_scheme)):
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Token kh√¥ng h·ª£p l·ªá ho·∫∑c ƒë√£ h·∫øt h·∫°n",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        userName: str = payload.get("sub")
        role: str = payload.get("role")
        if userName is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception

    user = await users_collection.find_one({"userName": userName})
    if user is None:
        raise credentials_exception
        
    return {
       "userName": user["userName"], 
        "role": user.get("role"),
        "id": str(user["_id"]),
        "email": user.get("email", ""),
        "phone": user.get("phone", ""),
        "age": user.get("age", ""),
        "hometown": user.get("hometown", ""),
        "insurance_id": user.get("insurance_id", ""),
        "height": user.get("height", ""),
        "weight": user.get("weight", ""),
        "gender": user.get("gender", ""),
        "nationality": user.get("nationality", ""),
        "assigned_doctor_id": user.get("assigned_doctor_id", None)
    }

# --- MODELS ---
class LoginRequest(BaseModel):
    userName: str
    password: str

class RegisterRequest(BaseModel):
    userName: str
    password: str
    role: str = "USER"

class GoogleLoginRequest(BaseModel):
    token: str

class UserProfileUpdate(BaseModel):
    email: str = None
    phone: str = None
    age: str = None       
    hometown: str = None
    insurance_id: str = None
    height: str = None
    weight: str = None
    gender: str = None
    nationality: str = None

class UpdateUsernameRequest(BaseModel):
    new_username: str

class AssignDoctorRequest(BaseModel):
    patient_id: str
    doctor_id: str

class DoctorNoteRequest(BaseModel):
    doctor_note: str

# --- API ENDPOINTS ---

@app.post("/api/register")
async def register(data: RegisterRequest):
    existing_user = await users_collection.find_one({"userName": data.userName})
    if existing_user:
        raise HTTPException(status_code=400, detail="T√™n t√†i kho·∫£n ƒë√£ ƒë∆∞·ª£c s·ª≠ d·ª•ng")
    
    hashed_password = bcrypt.hashpw(data.password.encode('utf-8'), bcrypt.gensalt())
    new_user = {
        "userName": data.userName,
        "password": hashed_password.decode('utf-8'),
        "role": data.role
    }

    await users_collection.insert_one(new_user)
    return {"message": "T·∫°o t√†i kho·∫£n th√†nh c√¥ng!"}

@app.post("/api/login")
async def login(data: LoginRequest):
    user = await users_collection.find_one({"userName": data.userName})
    if not user:
        raise HTTPException(status_code=400, detail="T√™n t√†i kho·∫£n kh√¥ng t·ªìn t·∫°i")
    
    try:
        password_input_bytes = data.password.encode('utf-8') 
        password_hash_bytes = user["password"].encode('utf-8')
        is_correct = bcrypt.checkpw(password_input_bytes, password_hash_bytes)
    except Exception as e:
        print(f"L·ªói: {e}")
        raise HTTPException(status_code=500, detail="L·ªói x·ª≠ l√Ω m·∫≠t kh·∫©u")

    if not is_correct:
          raise HTTPException(status_code=400, detail="Sai m·∫≠t kh·∫©u")

    token_data = {"sub": user["userName"], "role": user["role"]}
    access_token = create_access_token(token_data)
    
    return {
        "message": "ƒêƒÉng nh·∫≠p th√†nh c√¥ng",
        "access_token": access_token,
        "token_type": "bearer",
        "user_info": {
            "role": user.get("role"),
            "userName": user["userName"]
        }
    }

@app.get("/api/users/me")
async def read_users_me(current_user: dict = Depends(get_current_user)):
    return {
        "message": "ƒê√¢y l√† d·ªØ li·ªáu m·∫≠t",
        "user_info": current_user
    }

# --- API UPLOAD ---
@app.post("/api/upload-eye-image")
async def upload_eye_image(
    background_tasks: BackgroundTasks, 
    file: UploadFile = File(...), 
    current_user: dict = Depends(get_current_user)
):
    if not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File kh√¥ng h·ª£p l·ªá. Vui l√≤ng t·∫£i ·∫£nh.")

    try:
        # 1. Upload l√™n Cloudinary
        upload_result = cloudinary.uploader.upload(file.file, folder="aura_retina")
        image_url = upload_result.get("secure_url")
        
        # 2. L∆∞u v√†o DB (Tr·∫°ng th√°i Pending)
        record = {
            "user_id": current_user["id"],
            "userName": current_user["userName"],
            "image_url": image_url,
            "upload_date": datetime.utcnow(),
            "ai_analysis_status": "PENDING",
            "ai_result": "ƒêang ph√¢n t√≠ch..." 
        }
        
        new_record = await medical_records_collection.insert_one(record)
        new_id = str(new_record.inserted_id)

        # 3. G·ª≠i Task cho AI x·ª≠ l√Ω ng·∫ßm
        background_tasks.add_task(real_ai_analysis, new_id, image_url)

        return {
            "message": "Upload th√†nh c√¥ng! AI ƒëang ph√¢n t√≠ch...",
            "url": image_url,
            "record_id": new_id
        }

    except Exception as e:
        print(f"L·ªói Upload: {e}")
        raise HTTPException(status_code=500, detail="L·ªói khi upload ·∫£nh l√™n Cloudinary")

@app.get("/api/medical-records")
async def get_medical_records(current_user: dict = Depends(get_current_user)):
    cursor = medical_records_collection.find({"user_id": current_user["id"]}).sort("upload_date", -1)
    results = []
    async for document in cursor:
        results.append({
            "id": str(document["_id"]),
            "date": document["upload_date"].strftime("%d/%m/%Y"), 
            "time": document["upload_date"].strftime("%H:%M"),     
            "result": document["ai_result"],
            "status": "Ho√†n th√†nh" if document["ai_analysis_status"] == "COMPLETED" else "ƒêang x·ª≠ l√Ω",
            "image_url": document["image_url"]
        })
    return {"history": results}

@app.get("/api/medical-records/{record_id}")
async def get_single_record(record_id: str, current_user: dict = Depends(get_current_user)):
    try:
        query = {"_id": ObjectId(record_id)}
        if current_user["role"] != "DOCTOR":
            query["user_id"] = current_user["id"]

        record = await medical_records_collection.find_one(query)
        
        if not record:
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y h·ªì s∆° b·ªánh √°n")
            
        return {
            "id": str(record["_id"]),
            "date": record["upload_date"].strftime("%d/%m/%Y"),
            "time": record["upload_date"].strftime("%H:%M"),
            "result": record["ai_result"],
            "status": "Ho√†n th√†nh" if record["ai_analysis_status"] == "COMPLETED" else "ƒêang x·ª≠ l√Ω",
            "image_url": record["image_url"], # ·∫¢nh g·ªëc
            "annotated_image_url": record.get("annotated_image_url"), # ·∫¢nh AURA Scan
            "doctor_note": record.get("doctor_note", "") # Ch·ª©a c·∫£ ghi ch√∫ b√°c sƒ© v√† chi ti·∫øt AI
        }
    except Exception as e:
        print(f"L·ªói: {e}")
        raise HTTPException(status_code=400, detail="ID kh√¥ng h·ª£p l·ªá")

@app.put("/api/medical-records/{record_id}/note")
async def update_doctor_note(record_id: str, data: DoctorNoteRequest, current_user: dict = Depends(get_current_user)):
    if current_user["role"] != "DOCTOR":
        raise HTTPException(status_code=403, detail="Ch·ªâ B√°c sƒ© m·ªõi c√≥ quy·ªÅn th√™m ghi ch√∫.")
    try:
        result = await medical_records_collection.update_one(
            {"_id": ObjectId(record_id)},
            {"$set": {"doctor_note": data.doctor_note}}
        )
        if result.matched_count == 0:
            raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y h·ªì s∆°.")
        return {"message": "ƒê√£ l∆∞u ghi ch√∫ b√°c sƒ©."}
    except Exception as e:
        raise HTTPException(status_code=500, detail="L·ªói server.")

@app.post("/api/admin/assign-doctor")
async def assign_doctor(data: AssignDoctorRequest, current_user: dict = Depends(get_current_user)):
    if current_user["role"] != "ADMIN" and current_user["role"] != "DOCTOR":
        raise HTTPException(status_code=403, detail="Quy·ªÅn b·ªã t·ª´ ch·ªëi.")
    try:
        doctor = await users_collection.find_one({"_id": ObjectId(data.doctor_id), "role": "DOCTOR"})
        if not doctor: raise HTTPException(status_code=404, detail="ID b√°c sƒ© kh√¥ng t·ªìn t·∫°i.")
        
        result = await users_collection.update_one(
            {"_id": ObjectId(data.patient_id)},
            {"$set": {"assigned_doctor_id": data.doctor_id}}
        )
        if result.modified_count == 0: raise HTTPException(status_code=404, detail="Kh√¥ng t√¨m th·∫•y b·ªánh nh√¢n.")
        return {"message": "Ph√¢n c√¥ng b√°c sƒ© th√†nh c√¥ng.", "doctor_name": doctor["userName"]}
    except HTTPException as http_err: raise http_err
    except Exception as e: raise HTTPException(status_code=400, detail="L·ªói server.")

@app.post("/api/google-login")
async def google_login(data: GoogleLoginRequest):
    google_response = requests.get(f"https://www.googleapis.com/oauth2/v3/userinfo?access_token={data.token}")
    if google_response.status_code != 200:
        raise HTTPException(status_code=400, detail="Token Google kh√¥ng h·ª£p l·ªá")
    google_user = google_response.json()
    email = google_user.get('email')
    name = google_user.get('name', 'Google User')
    if not email: raise HTTPException(status_code=400, detail="Kh√¥ng l·∫•y ƒë∆∞·ª£c email")

    user = await users_collection.find_one({"email": email})
    is_new_user = False
    if not user:
        new_user = {
            "userName": email, "email": email, "password": "", "role": "USER",
            "auth_provider": "google", "full_name": name, "created_at": datetime.utcnow()
        }
        result = await users_collection.insert_one(new_user)
        user = new_user; user["_id"] = result.inserted_id; is_new_user = True
    else:
        if user.get("userName") == email: is_new_user = True
            
    token_data = {"sub": user["userName"], "role": user.get("role", "USER")}
    access_token = create_access_token(token_data)
    return {"message": "ƒêƒÉng nh·∫≠p Google th√†nh c√¥ng", "access_token": access_token, "token_type": "bearer", "user_info": {"userName": user["userName"], "role": user.get("role", "USER"), "email": user.get("email")}, "is_new_user": is_new_user}

@app.put("/api/users/set-username")
async def set_username(data: UpdateUsernameRequest, current_user: dict = Depends(get_current_user)):
    user_id = current_user["id"]
    new_username = data.new_username.strip()
    if len(new_username) < 3: raise HTTPException(status_code=400, detail="T√™n qu√° ng·∫Øn")
    existing_user = await users_collection.find_one({"userName": new_username})
    if existing_user: raise HTTPException(status_code=400, detail="T√™n ƒë√£ t·ªìn t·∫°i")
    await users_collection.update_one({"_id": ObjectId(user_id)}, {"$set": {"userName": new_username}})
    new_token_data = {"sub": new_username, "role": current_user["role"]}
    new_access_token = create_access_token(new_token_data)
    return {"message": "C·∫≠p nh·∫≠t th√†nh c√¥ng", "new_access_token": new_access_token, "new_username": new_username}

@app.put("/api/users/profile")
async def update_user_profile(data: UserProfileUpdate, current_user: dict = Depends(get_current_user)):
    try:
        user_id = current_user["id"]
        if data.email:
            existing = await users_collection.find_one({"email": data.email, "_id": {"$ne": ObjectId(user_id)}})
            if existing: raise HTTPException(status_code=400, detail="Email ƒë√£ d√πng")
        if data.phone:
            existing = await users_collection.find_one({"phone": data.phone, "_id": {"$ne": ObjectId(user_id)}})
            if existing: raise HTTPException(status_code=400, detail="SƒêT ƒë√£ d√πng")
        update_data = {k: v for k, v in data.dict().items() if v is not None}
        await users_collection.update_one({"_id": ObjectId(user_id)}, {"$set": update_data})
        return {"message": "C·∫≠p nh·∫≠t h·ªì s∆° th√†nh c√¥ng", "data": update_data}
    except HTTPException as e: raise e
    except Exception as e: raise HTTPException(status_code=500, detail="L·ªói server")

@app.get("/api/doctor/my-patients")
async def get_doctor_assigned_patients(current_user: dict = Depends(get_current_user)):
    if current_user["role"] != "DOCTOR": raise HTTPException(status_code=403, detail="Quy·ªÅn b·ªã t·ª´ ch·ªëi.")
    doctor_id = current_user["id"]
    patient_cursor = users_collection.find({"assigned_doctor_id": doctor_id}).sort("userName", 1)
    patients_list = []
    async for patient in patient_cursor:
        patient_id = str(patient["_id"])
        latest_record = await medical_records_collection.find_one({"user_id": patient_id}, sort=[("upload_date", -1)])
        patients_list.append({
            "id": patient_id, "userName": patient["userName"], "email": patient.get("email", "N/A"), "phone": patient.get("phone", "N/A"), "status": patient.get("status", "ACTIVE"),
            "latest_scan": {"record_id": str(latest_record["_id"]) if latest_record else None, "date": latest_record["upload_date"].strftime("%d/%m/%Y") if latest_record else "Ch∆∞a c√≥", "result": latest_record["ai_result"] if latest_record else "Ch∆∞a c√≥ d·ªØ li·ªáu", "ai_status": latest_record["ai_analysis_status"] if latest_record else "NA"}
        })
    return {"patients": patients_list}

@app.get("/api/admin/users")
async def get_all_users(current_user: dict = Depends(get_current_user)):
    if current_user["role"] != "ADMIN": raise HTTPException(status_code=403, detail="Quy·ªÅn b·ªã t·ª´ ch·ªëi.")
    user_cursor = users_collection.find() 
    users_list = []
    async for user in user_cursor:
        users_list.append({"id": str(user["_id"]), "userName": user["userName"], "email": user.get("email", ""), "role": user.get("role", "USER"), "status": user.get("status", "ACTIVE"), "assigned_doctor_id": user.get("assigned_doctor_id", None)})
    return {"users": users_list}

@app.get("/api/chats")
async def get_chats(current_user: dict = Depends(get_current_user)):
    user_id = current_user["id"]
    user_role = current_user["role"]
    chats = []
    if user_role == "DOCTOR":
        patients_cursor = users_collection.find({"assigned_doctor_id": user_id})
        async for patient in patients_cursor:
            chats.append({"id": str(patient["_id"]), "sender": patient["userName"], "preview": "B√°c sƒ© ∆°i, t√¥i ƒë√£ c√≥ k·∫øt qu·∫£ ch·ª•p m·ªõi...", "time": "V·ª´a xong", "unread": True, "interlocutor_id": str(patient["_id"])})
    elif user_role == "USER":
        assigned_doc_id = current_user.get("assigned_doctor_id")
        if assigned_doc_id:
            try:
                doctor = await users_collection.find_one({"_id": ObjectId(assigned_doc_id)})
                if doctor: chats.append({"id": str(doctor["_id"]), "sender": f"BS. {doctor['userName']}", "preview": "Ch√†o b·∫°n, h√£y th∆∞·ªùng xuy√™n c·∫≠p nh·∫≠t t√¨nh tr·∫°ng nh√©.", "time": "H√¥m nay", "unread": True, "interlocutor_id": str(doctor["_id"])})
            except: pass
        chats.append({"id": "system_01", "sender": "H·ªá th·ªëng AURA", "preview": "Ch√†o m·ª´ng b·∫°n! H√£y ch·ª•p ·∫£nh ƒë√°y m·∫Øt ƒë·ªÉ b·∫Øt ƒë·∫ßu.", "time": "H√¥m qua", "unread": False, "interlocutor_id": "system"})
    return {"chats": chats}